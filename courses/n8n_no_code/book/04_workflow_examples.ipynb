{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Examples\n",
    "\n",
    "This chapter demonstrates three common workflow patterns using the nodes from the previous chapter. Import the pre-built workflows, run them, and observe how the nodes work together.\n",
    "\n",
    "**Workflow files:** The JSON files are in `courses/n8n_no_code/01_intro_patterns/workflows/`\n",
    "\n",
    "**Note on credentials:** These workflows require API credentials for an AI provider (OpenRouter, OpenAI, or Google). If you do not have credentials set up, you can still explore the workflow structure and understand what each node would do.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Import and Run a Workflow\n",
    "\n",
    "**Import:**\n",
    "1. In n8n, click **Workflows** in the left sidebar\n",
    "2. Click **Add Workflow**\n",
    "3. Click the **three-dot menu (⋮)** in the top-right\n",
    "4. Select **Import from File**\n",
    "5. Choose the `.json` file\n",
    "6. Click **Save**\n",
    "\n",
    "**Run:**\n",
    "1. Open the workflow in the editor\n",
    "2. Make sure credentials are set up (Settings → Credentials)\n",
    "3. Click **Execute Workflow** in the top toolbar\n",
    "4. Click any node to see its output in the right panel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 1: Prompt Chaining\n",
    "\n",
    "**File:** `01_prompt_chaining.json`\n",
    "\n",
    "### What This Pattern Does\n",
    "\n",
    "Breaks a complex task into sequential LLM calls, where each call builds on the previous result.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "Trigger → Set (input) → LLM 1 → Set (save) → LLM 2 → Set (save) → LLM 3\n",
    "```\n",
    "\n",
    "### Nodes in This Workflow\n",
    "\n",
    "| Node | What it does |\n",
    "|------|-------------|\n",
    "| Manual Trigger | Starts the workflow |\n",
    "| Input (Set) | Defines topic, audience, constraints |\n",
    "| Chat Model | Provides the AI model |\n",
    "| Step 1: Create Outline | LLM generates an outline |\n",
    "| Store Outline (Set) | Saves the outline with a clear name |\n",
    "| Step 2: Improve Outline | LLM refines the outline |\n",
    "| Store Improved (Set) | Saves the improved version |\n",
    "| Step 3: Draft Document | LLM writes the final document |\n",
    "\n",
    "### What to Observe\n",
    "\n",
    "- **Input node:** See the starting data (topic, audience, constraints)\n",
    "- **Each LLM node:** Click to see the prompt sent and response received\n",
    "- **Each Set node:** See how intermediate results are saved with clear field names\n",
    "- **Final output:** The completed document in the `text` field\n",
    "\n",
    "### Why Use Checkpoints (Set Nodes)?\n",
    "\n",
    "The Set nodes between LLM calls serve as \"checkpoints\":\n",
    "- Save each result with a descriptive name (`outline`, `improved_outline`)\n",
    "- Make debugging easier — you can see exactly what each step produced\n",
    "- Allow pinning at specific steps to avoid re-running expensive LLM calls\n",
    "\n",
    "### Try This\n",
    "\n",
    "Change the `topic` field in the first Set node to a different subject. Run the workflow again and observe how the entire chain produces different output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pattern 2: Routing\n",
    "\n",
    "**File:** `02_routing.json`\n",
    "\n",
    "### What This Pattern Does\n",
    "\n",
    "Uses an LLM to classify input, then routes data to different branches based on the classification.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "Trigger → Set (input) → LLM (classify) → Set (route) → Switch → [Branch A]\n",
    "                                                              → [Branch B]\n",
    "                                                              → [Fallback]\n",
    "```\n",
    "\n",
    "### Nodes in This Workflow\n",
    "\n",
    "| Node | What it does |\n",
    "|------|-------------|\n",
    "| Manual Trigger | Starts the workflow |\n",
    "| Input (Set) | Defines the input to classify (e.g., support ticket) |\n",
    "| Chat Model | Provides the AI model |\n",
    "| Classifier (LLM) | Outputs a classification label |\n",
    "| Store Route (Set) | Saves the label in a `route` field |\n",
    "| Switch | Routes data based on `{{ $json.route }}` |\n",
    "| Branch nodes | Different processing for each route |\n",
    "\n",
    "### How the Classifier Works\n",
    "\n",
    "The classifier LLM prompt explicitly lists allowed labels:\n",
    "\n",
    "```\n",
    "Classify this ticket into one of these categories:\n",
    "- refund\n",
    "- support\n",
    "- sales\n",
    "\n",
    "Output only the category name, nothing else.\n",
    "```\n",
    "\n",
    "The LLM outputs a single word (e.g., `refund`), which the Switch node uses to route.\n",
    "\n",
    "### What to Observe\n",
    "\n",
    "- **Classifier LLM:** See the prompt and the classification result\n",
    "- **Set node after classifier:** See the `route` field being saved\n",
    "- **Switch node:** Click to see which output branch received data (only one will have data)\n",
    "- **Branch nodes:** Only one branch will have executed\n",
    "\n",
    "### Try This\n",
    "\n",
    "Change the input data to trigger a different route. For example, change a refund request to a technical question. Run again and observe which branch activates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pattern 3: Parallelization\n",
    "\n",
    "**File:** `03_parallelization.json`\n",
    "\n",
    "### What This Pattern Does\n",
    "\n",
    "Runs multiple LLM calls in parallel, then combines the results.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "Trigger → Set (input) → [LLM A: analyze] → Set (save) ─┐\n",
    "                      → [LLM B: extract] → Set (save) ─┼→ Merge → LLM (final)\n",
    "                      → [LLM C: draft]   → Set (save) ─┘\n",
    "```\n",
    "\n",
    "### Nodes in This Workflow\n",
    "\n",
    "| Node | What it does |\n",
    "|------|-------------|\n",
    "| Manual Trigger | Starts the workflow |\n",
    "| Input (Set) | Defines the input data |\n",
    "| Chat Model | Provides the AI model |\n",
    "| Branch A: LLM | Performs analysis A (e.g., sentiment) |\n",
    "| Branch A: Set | Saves result as `sentiment` |\n",
    "| Branch B: LLM | Performs analysis B (e.g., extract facts) |\n",
    "| Branch B: Set | Saves result as `facts` |\n",
    "| Branch C: LLM | Performs analysis C (e.g., draft reply) |\n",
    "| Branch C: Set | Saves result as `draft` |\n",
    "| Merge | Combines all results into one item |\n",
    "| Final LLM | Uses combined data to produce final output |\n",
    "\n",
    "### Why Use Parallel Branches?\n",
    "\n",
    "- **Speed:** Parallel branches run at the same time, not sequentially\n",
    "- **Independence:** Each analysis can focus on one thing\n",
    "- **Modularity:** Easy to add or remove branches\n",
    "\n",
    "### How the Merge Node Works\n",
    "\n",
    "With \"Combine by Position\" mode:\n",
    "- Each branch outputs one item\n",
    "- Merge combines all fields into one item:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"sentiment\": \"positive\",\n",
    "  \"facts\": [\"fact1\", \"fact2\"],\n",
    "  \"draft\": \"Here is a draft reply...\"\n",
    "}\n",
    "```\n",
    "\n",
    "### What to Observe\n",
    "\n",
    "- **Parallel branches:** Multiple LLM nodes that run at the same time\n",
    "- **Set nodes in each branch:** Each saves its result with a unique field name\n",
    "- **Merge node:** Click to see all fields combined (switch to JSON view)\n",
    "- **Final LLM:** Uses data from all branches in its prompt\n",
    "\n",
    "### Try This\n",
    "\n",
    "Click the Merge node and switch to JSON view. Verify that all fields from all branches are present. Then click the final LLM and check that its prompt references data from each branch."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## AI Agent Node (Minimal Intro)\n\nThe **AI Agent** node is a workflow step that can **decide what to do next** instead of following a single fixed prompt.\n\n- **Tools:** optional actions the agent can call (e.g., calculator, HTTP request, search). Think: \"abilities\".\n- **Memory:** optional context the agent can carry across steps so it stays consistent.\n- **Loop (plan → act → check):** the agent can iterate: decide a plan, use a tool (act), check results, and stop when done.\n\n**Tip:** Start simple—use **one tool** (or none) and keep runs in **manual test mode** to avoid accidental costs.\n\nSee the **AI Agent Examples** chapter for a hands-on walkthrough.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pattern Summary\n",
    "\n",
    "| Pattern | When to use | Key nodes |\n",
    "|---------|-------------|------------|\n",
    "| **Prompt Chaining** | Complex tasks that benefit from step-by-step refinement | Multiple LLM Chains in sequence |\n",
    "| **Routing** | Different handling based on input type | LLM (classifier) + Switch |\n",
    "| **Parallelization** | Independent analyses that can run simultaneously | Multiple branches + Merge |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tips for Building Your Own Workflows\n",
    "\n",
    "1. **Start simple.** Build one node at a time and test frequently.\n",
    "\n",
    "2. **Use descriptive node names.** \"Step 1: Create Outline\" is better than \"LLM Chain.\"\n",
    "\n",
    "3. **Pin data often.** After any successful LLM call, pin the result before working on the next node.\n",
    "\n",
    "4. **Check the Output panel.** Switch between Table and JSON views to understand your data.\n",
    "\n",
    "5. **Use Set nodes as checkpoints.** Save intermediate results with clear field names.\n",
    "\n",
    "6. **Test routing with different inputs.** Make sure all branches work, not just the happy path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Glossary\n",
    "\n",
    "| Term | Definition |\n",
    "|------|------------|\n",
    "| **Workflow** | A sequence of connected nodes that automate a task |\n",
    "| **Trigger** | The first node; defines what starts the workflow |\n",
    "| **Node** | A single step in a workflow |\n",
    "| **Connection** | Solid = data flow; Dotted = capability |\n",
    "| **Execution** | One complete run of a workflow |\n",
    "| **Item** | One unit of data with `.json` property |\n",
    "| **Expression** | Dynamic value using `{{ $json.field }}` |\n",
    "| **Pinned Data** | Saved output to reuse without re-running |\n",
    "| **Credential** | Securely stored API key |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Official Documentation Links\n",
    "\n",
    "| Topic | Link |\n",
    "|-------|------|\n",
    "| Workflows | [docs.n8n.io/workflows](https://docs.n8n.io/workflows/) |\n",
    "| Executions | [docs.n8n.io/workflows/executions](https://docs.n8n.io/workflows/executions/) |\n",
    "| Data Pinning | [docs.n8n.io/data/data-pinning](https://docs.n8n.io/data/data-pinning/) |\n",
    "| Expressions | [docs.n8n.io/code/expressions](https://docs.n8n.io/code/expressions/) |\n",
    "| Manual Trigger | [docs.n8n.io/.../manualtrigger](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.manualtrigger/) |\n",
    "| Edit Fields (Set) | [docs.n8n.io/.../set](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/) |\n",
    "| AI Nodes | [docs.n8n.io/.../cluster-nodes](https://docs.n8n.io/integrations/builtin/cluster-nodes/) |\n",
    "| Basic LLM Chain | [docs.n8n.io/.../chainllm](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/) |\n",
    "| Switch | [docs.n8n.io/.../switch](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.switch/) |\n",
    "| Merge | [docs.n8n.io/.../merge](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.merge/) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}