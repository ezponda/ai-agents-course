{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Workflow Examples\n\nThis chapter demonstrates three common workflow patterns using the nodes from the previous chapter. Import the pre-built workflows, run them, and observe how the nodes work together.\n\n**Workflow files:** The JSON files are in `courses/n8n_no_code/workflows/`\n\n**Note on credentials:** These workflows require API credentials for an AI provider (OpenRouter, OpenAI, or Google). If you do not have credentials set up, you can still explore the workflow structure and understand what each node would do.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Import and Run a Workflow\n",
    "\n",
    "**Import:**\n",
    "1. In n8n, click **Workflows** in the left sidebar\n",
    "2. Click **Add Workflow**\n",
    "3. Click the **three-dot menu (⋮)** in the top-right\n",
    "4. Select **Import from File**\n",
    "5. Choose the `.json` file\n",
    "6. Click **Save**\n",
    "\n",
    "**Run:**\n",
    "1. Open the workflow in the editor\n",
    "2. Make sure credentials are set up (Settings → Credentials)\n",
    "3. Click **Execute Workflow** in the top toolbar\n",
    "4. Click any node to see its output in the right panel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pattern 1: Prompt Chaining\n\n**File:** `01_prompt_chaining.json`\n\n> **Import via URL** (copy and paste in n8n → Import from URL):\n> ```\n> https://raw.githubusercontent.com/ezponda/ai-agents-course/main/courses/n8n_no_code/workflows/01_prompt_chaining.json\n> ```\n> \n> **Download:** [01_prompt_chaining.json](https://github.com/ezponda/ai-agents-course/raw/main/courses/n8n_no_code/workflows/01_prompt_chaining.json)\n\n### Nodes in This Pattern\n\nThis pattern uses nodes you already know from Quick Start:\n\n| Node | What it does |\n|------|--------------|\n| **Manual Trigger** | Starts the workflow when you click \"Test workflow\" |\n| **Edit Fields (Set)** | Creates or transforms data fields |\n| **Basic LLM Chain** | Sends a prompt to an AI model and returns the response |\n\nThe difference here: we chain **multiple** Basic LLM Chains in sequence, where each uses the previous one's output.\n\n### What Problem This Solves\n\nBreaking a complex writing task into smaller steps improves quality. Instead of asking an LLM to \"write a memo\" in one shot, you ask it to: (1) create an outline, (2) improve the outline, (3) write the final draft. Each step builds on the previous result.\n\n### Node-by-Node Walkthrough\n\n| Node | Type | What it does |\n|------|------|-------------|\n| **Run: Prompt Chaining** | Manual Trigger | Starts the workflow |\n| **Input — Writing Brief** | Set | Creates fields: `topic`, `audience`, `constraints` |\n| **Step 1 — Create Outline** | Basic LLM Chain | Generates an outline → outputs `text` |\n| **Store Outline** | Set | Saves `{{ $json.text }}` as `outline` |\n| **Step 2 — Improve Outline** | Basic LLM Chain | Refines the outline using `{{ $json.outline }}` → outputs `text` |\n| **Store Improved Outline** | Set | Saves `{{ $json.text }}` as `improved_outline` |\n| **Step 3 — Draft Memo** | Basic LLM Chain | Writes final memo using `{{ $json.improved_outline }}` → outputs `text` |\n| **Output — Final Memo** | Set | Saves `{{ $json.text }}` as `final_memo` (uses `keepOnlySet` to remove other fields) |\n\n**Sub-node:** One `OpenRouter Chat Model` is shared by all three LLM Chain nodes (connected via dotted lines).\n\n### Prompts Used\n\nEach step uses a different **role** and **rules**. This is why chaining works better than one big prompt.\n\n**Step 1 — Create Outline:**\n```\nSystem: You are a writing assistant.\nCreate a clear outline for the memo.\n\nRules:\n- 5–7 sections\n- Include where the benefits bullets and risks bullet will go\n- Output ONLY the outline\n```\n\n**Step 2 — Improve Outline:**\n```\nSystem: You are a strict editor.\nImprove the outline using this checklist:\n- Logical flow\n- Clear headings\n- Covers constraints (benefits + risks)\n- Non-technical wording\n\nOutput ONLY the improved outline (no commentary).\n```\n\n**Step 3 — Draft Memo:**\n```\nSystem: You are a business writer.\nWrite the memo based on the outline.\n\nRules:\n- Follow the outline order\n- Keep under 400 words\n- Use clear, non-technical language\n- Include exactly: 3 benefit bullets + 1 risk bullet\n\nOutput ONLY the memo text.\n```\n\n**Why this works:** Each step has a focused role (assistant → editor → writer), specific constraints, and ends with \"Output ONLY...\" to prevent extra commentary.\n\n### Data Flow\n\n```\nINPUT                          OUTPUT\n─────                          ──────\nTrigger: { }\n    ↓\nWriting Brief: { topic, audience, constraints }\n    ↓\nStep 1 LLM: { text: \"1. Introduction...\" }\n    ↓\nStore Outline: { outline: \"1. Introduction...\" }\n    ↓\nStep 2 LLM: { text: \"1. Executive Summary...\" }\n    ↓\nStore Improved: { improved_outline: \"1. Executive Summary...\" }\n    ↓\nStep 3 LLM: { text: \"MEMO: Why We Should...\" }\n    ↓\nFinal Output: { final_memo: \"MEMO: Why We Should...\" }\n```\n\n### What to Observe\n\n1. Click **Input — Writing Brief** → see the starting data\n2. Click **Step 1 — Create Outline** → see the LLM's outline in `text`\n3. Click **Store Outline** → see the same content now saved as `outline`\n4. Follow this pattern through each step to see how data transforms"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Pattern 2: Routing\n\n**File:** `02_routing.json`\n\n> **Import via URL** (copy and paste in n8n → Import from URL):\n> ```\n> https://raw.githubusercontent.com/ezponda/ai-agents-course/main/courses/n8n_no_code/workflows/02_routing.json\n> ```\n> \n> **Download:** [02_routing.json](https://github.com/ezponda/ai-agents-course/raw/main/courses/n8n_no_code/workflows/02_routing.json)\n\n### Meet the Node: Switch\n\nThis pattern introduces a new node: **Switch**.\n\n| Property | Description |\n|----------|-------------|\n| **Purpose** | Routes data to different branches based on conditions |\n| **How it works** | Checks a value and sends data to the matching output |\n| **Multiple outputs** | Each condition creates a separate output branch (solid line) |\n\n**Configuration:**\n1. **Mode:** Choose \"Rules\" for condition-based routing\n2. **Data Type:** Usually \"String\" when routing on text values\n3. **Value 1:** The field to check, e.g., `{{ $json.route }}`\n4. **Operation:** Usually \"Equals\" for exact matching\n5. **Value 2:** The value to match, e.g., `refund`\n\nAdd more rules to create more branches. The Switch sends data only to the branch where the condition matches.\n\n**See Node Toolbox for full documentation.**\n\n### What Problem This Solves\n\nDifferent inputs need different handling. A support ticket about refunds should go to a refund specialist prompt, while an order status question goes elsewhere. Routing uses an LLM to classify the input, then a Switch node sends it down the right path.\n\n### Node-by-Node Walkthrough\n\n| Node | Type | What it does |\n|------|------|-------------|\n| **Run: Ticket Routing** | Manual Trigger | Starts the workflow |\n| **Input — Support Ticket** | Set | Creates fields: `ticket_subject`, `ticket_body` |\n| **Router — Choose Route** | Basic LLM Chain | Classifies ticket → outputs `text` (e.g., `refund`) |\n| **Store Route** | Set | Saves `{{ $json.text.trim() }}` as `route` |\n| **Switch — Route** | Switch | Checks `{{ $json.route }}` and sends to one branch |\n| **Refund Specialist — Draft Reply** | Basic LLM Chain | Writes refund-specific reply → outputs `text` |\n| **Order Status Specialist — Draft Reply** | Basic LLM Chain | Writes order status reply → outputs `text` |\n| **Support Specialist — Draft Reply** | Basic LLM Chain | Writes general support reply → outputs `text` |\n| **Output — Refund Reply** | Set | Saves `{{ $json.text }}` as `reply`, adds `route: \"refund\"` |\n| **Output — Order Status Reply** | Set | Saves `{{ $json.text }}` as `reply`, adds `route: \"order_status\"` |\n| **Output — Support Reply** | Set | Saves `{{ $json.text }}` as `reply`, adds `route: \"support\"` |\n\n### Prompts Used\n\n**Router — Choose Route (the classifier):**\n```\nSystem: You route customer support tickets.\n\nChoose exactly ONE route label, lowercase, no punctuation:\n- refund\n- order_status\n- support\n\nReturn ONLY the label.\n```\n\n**Why this works:** The prompt forces clean output (lowercase, no punctuation, ONLY the label) so the Switch node can match exactly.\n\n**Refund Specialist:**\n```\nSystem: You are a customer support specialist for refunds.\nWrite a short, professional reply.\n\nRules:\n- Acknowledge the issue\n- Ask for any missing info (only if needed)\n- Explain next steps and expected timeline\n- Keep it under 120 words\n```\n\n**Order Status Specialist:**\n```\nSystem: You are a customer support specialist for order status.\nWrite a short, professional reply.\n\nRules:\n- Confirm you are checking the order\n- Ask for order number if missing\n- Provide what you can and what you still need\n- Keep it under 120 words\n```\n\n**Support Specialist:**\n```\nSystem: You are a general customer support specialist.\nWrite a short, professional reply.\n\nRules:\n- Clarify the problem\n- Ask 1–2 targeted questions (only if needed)\n- Offer a next step\n- Keep it under 120 words\n```\n\n### Key Expression: Accessing Earlier Node Data\n\nThe specialist nodes need the original ticket data, but they come after the Switch. They use this expression pattern:\n\n```\n{{ $node['Input — Support Ticket'].json.ticket_subject }}\n{{ $node['Input — Support Ticket'].json.ticket_body }}\n```\n\nThis accesses data from a specific earlier node by name. Useful when you need to \"reach back\" past intermediate nodes.\n\n### Data Flow\n\n```\nINPUT                          OUTPUT\n─────                          ──────\nTrigger: { }\n    ↓\nSupport Ticket: { ticket_subject, ticket_body }\n    ↓\nRouter LLM: { text: \"refund\" }\n    ↓\nStore Route: { route: \"refund\", ticket_subject, ticket_body }\n    ↓\nSwitch: routes to ONE branch based on {{ $json.route }}\n    ↓\n[Refund Specialist]: { text: \"Dear Jamie, I apologize...\" }\n    ↓\nOutput — Refund Reply: { reply: \"Dear Jamie, I apologize...\", route: \"refund\" }\n```\n\n### What to Observe\n\n1. Click **Router — Choose Route** → see the classification in `text` (e.g., `refund`)\n2. Click **Store Route** → see `route` field added\n3. Click **Switch — Route** → only ONE output branch has data\n4. Click the active specialist node → see the tailored reply"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Pattern 3: Parallelization\n\n**File:** `03_parallelization.json`\n\n> **Import via URL** (copy and paste in n8n → Import from URL):\n> ```\n> https://raw.githubusercontent.com/ezponda/ai-agents-course/main/courses/n8n_no_code/workflows/03_parallelization.json\n> ```\n> \n> **Download:** [03_parallelization.json](https://github.com/ezponda/ai-agents-course/raw/main/courses/n8n_no_code/workflows/03_parallelization.json)\n\n### Meet the Node: Merge\n\nThis pattern introduces a new node: **Merge**.\n\n| Property | Description |\n|----------|-------------|\n| **Purpose** | Combines data from multiple branches into one |\n| **Multiple inputs** | Receives data from 2+ parallel branches |\n| **Output** | One combined item (or list) with all fields |\n\n**Key Modes:**\n| Mode | What it does |\n|------|--------------|\n| **Combine by Position** | Pairs items by index (1st + 1st, 2nd + 2nd). Best when each branch outputs one item. |\n| **Combine by Fields** | Matches items by a common field value |\n| **Append** | Puts all items into one list |\n\nIn this workflow, we use **Combine by Position** because each branch outputs exactly one item.\n\n**See Node Toolbox for full documentation.**\n\n### What Problem This Solves\n\nSome tasks have independent parts that can run at the same time. Analyzing a customer email for facts, sentiment, and drafting a reply are independent—they don't need each other's results. Running them in parallel is faster, and you can combine the results at the end for a final, informed response.\n\n### Node-by-Node Walkthrough\n\n| Node | Type | What it does |\n|------|------|-------------|\n| **Run: Parallelization** | Manual Trigger | Starts the workflow |\n| **Input — Customer Email** | Set | Creates fields: `email_subject`, `email_body` |\n| **Branch A — Extract Facts** | Basic LLM Chain | Extracts facts as JSON → outputs `text` |\n| **Store Facts** | Set | Saves `{{ $json.text }}` as `facts_json` |\n| **Branch B — Sentiment & Urgency** | Basic LLM Chain | Analyzes sentiment → outputs `text` |\n| **Store Sentiment** | Set | Saves `{{ $json.text }}` as `sentiment_json` |\n| **Branch C — Draft Reply** | Basic LLM Chain | Drafts initial reply → outputs `text` |\n| **Store Draft Reply** | Set | Saves `{{ $json.text }}` as `draft_reply` |\n| **Merge A+B** | Merge | Combines `facts_json` + `sentiment_json` (mode: Combine by Position) |\n| **Merge (A+B)+C** | Merge | Adds `draft_reply` to the combined data |\n| **Finalize — One Improved Reply** | Basic LLM Chain | Uses all three fields → outputs `text` |\n| **Output — Final Reply** | Set | Saves `{{ $json.text }}` as `final_reply` |\n\n### Prompts Used\n\n**Branch A — Extract Facts:**\n```\nSystem: Extract key facts from the email.\nReturn STRICT JSON with keys:\ncustomer_name, issue, deadline, requested_action, missing_info (array).\nReturn JSON only.\n```\n\n**Branch B — Sentiment & Urgency:**\n```\nSystem: Classify sentiment and urgency.\nReturn STRICT JSON with keys:\nsentiment (positive|neutral|negative), urgency (low|medium|high), risk_flags (array).\nReturn JSON only.\n```\n\n**Branch C — Draft Reply:**\n```\nSystem: Draft a helpful customer support email reply.\nRules:\n- Friendly and concise\n- Ask for missing info only if needed\n- Offer 1–2 concrete next steps\n- Under 140 words\n\nOutput ONLY the reply text.\n```\n\n**Finalize — One Improved Reply:**\n```\nSystem: You are a senior support agent.\nYou will receive:\n- facts_json (extracted facts)\n- sentiment_json (sentiment & urgency)\n- draft_reply (initial draft)\n\nTask:\n1) Improve the draft to match urgency and include any critical missing info questions.\n2) Keep it under 160 words.\n3) Output ONLY the final reply text.\n```\n\n### Example JSON Outputs\n\n**Branch A (facts_json):**\n```json\n{\n  \"customer_name\": \"Sam\",\n  \"issue\": \"Can't log in after password reset, invalid token error\",\n  \"deadline\": \"end of day\",\n  \"requested_action\": \"Help accessing invoices\",\n  \"missing_info\": []\n}\n```\n\n**Branch B (sentiment_json):**\n```json\n{\n  \"sentiment\": \"negative\",\n  \"urgency\": \"high\",\n  \"risk_flags\": [\"access issue\", \"time-sensitive\", \"repeated attempts\"]\n}\n```\n\n### Data Flow\n\n```\nINPUT                          OUTPUT\n─────                          ──────\nTrigger: { }\n    ↓\nCustomer Email: { email_subject, email_body }\n    ↓ ↓ ↓ (splits into 3 parallel branches)\n    \nBranch A: { text: '{\"customer_name\":\"Sam\",...}' }\n    ↓\nStore Facts: { facts_json: '{\"customer_name\":\"Sam\",...}' }\n\nBranch B: { text: '{\"sentiment\":\"negative\",\"urgency\":\"high\",...}' }\n    ↓\nStore Sentiment: { sentiment_json: '{\"sentiment\":\"negative\",...}' }\n\nBranch C: { text: \"Hi Sam, I understand...\" }\n    ↓\nStore Draft Reply: { draft_reply: \"Hi Sam, I understand...\" }\n    \n    ↓ (merge all three)\nAfter Merge: { facts_json, sentiment_json, draft_reply }\n    ↓\nFinalize LLM: { text: \"Dear Sam, I sincerely apologize...\" }\n    ↓\nFinal Output: { final_reply: \"Dear Sam, I sincerely apologize...\" }\n```\n\n### What to Observe\n\n1. Click **Input — Customer Email** → see the starting data\n2. Click each **Branch** node → see different analyses running independently\n3. Click **Merge (A+B)+C** → switch to JSON view to see all three fields combined\n4. Click **Finalize** → see how the final LLM uses `{{ $json.facts_json }}`, `{{ $json.sentiment_json }}`, and `{{ $json.draft_reply }}`"
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## AI Agent Node (Minimal Intro)\n\nThe **AI Agent** node is a workflow step that can **decide what to do next** instead of following a single fixed prompt.\n\n- **Tools:** optional actions the agent can call (e.g., calculator, HTTP request, search). Think: \"abilities\".\n- **Memory:** optional context the agent can carry across steps so it stays consistent.\n- **Loop (plan → act → check):** the agent can iterate: decide a plan, use a tool (act), check results, and stop when done.\n\n**Tip:** Start simple—use **one tool** (or none) and keep runs in **manual test mode** to avoid accidental costs.\n\nSee the **AI Agent Examples** chapter for a hands-on walkthrough.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pattern Summary\n",
    "\n",
    "| Pattern | When to use | Key nodes |\n",
    "|---------|-------------|------------|\n",
    "| **Prompt Chaining** | Complex tasks that benefit from step-by-step refinement | Multiple LLM Chains in sequence |\n",
    "| **Routing** | Different handling based on input type | LLM (classifier) + Switch |\n",
    "| **Parallelization** | Independent analyses that can run simultaneously | Multiple branches + Merge |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tips for Building Your Own Workflows\n",
    "\n",
    "1. **Start simple.** Build one node at a time and test frequently.\n",
    "\n",
    "2. **Use descriptive node names.** \"Step 1: Create Outline\" is better than \"LLM Chain.\"\n",
    "\n",
    "3. **Pin data often.** After any successful LLM call, pin the result before working on the next node.\n",
    "\n",
    "4. **Check the Output panel.** Switch between Table and JSON views to understand your data.\n",
    "\n",
    "5. **Use Set nodes as checkpoints.** Save intermediate results with clear field names.\n",
    "\n",
    "6. **Test routing with different inputs.** Make sure all branches work, not just the happy path."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}