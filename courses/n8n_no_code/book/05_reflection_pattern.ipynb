{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Reflection Pattern\n",
    "\n",
    "This chapter reveals a key insight: **AI agents are just automated loops**.\n",
    "\n",
    "We'll implement the same task two ways â€” showing how the agent automates what you can build manually.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## What is Reflection?\n\nThe **Reflection pattern** is a loop where the AI:\n1. **Generates** an output\n2. **Critiques** its own output\n3. **Refines** based on the critique\n4. **Repeats** until satisfied\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        REFLECTION LOOP                              â”‚\nâ”‚                                                                     â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\nâ”‚    â”‚ GENERATE â”‚â”€â”€â”€â”€â”€â–¶â”‚ CRITIQUE â”‚â”€â”€â”€â”€â”€â–¶â”‚  REFINE  â”‚                â”‚\nâ”‚    â”‚          â”‚      â”‚          â”‚      â”‚          â”‚                â”‚\nâ”‚    â”‚  Draft   â”‚      â”‚  Check   â”‚      â”‚   Fix    â”‚                â”‚\nâ”‚    â”‚  output  â”‚      â”‚  issues  â”‚      â”‚  issues  â”‚                â”‚\nâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚\nâ”‚                           â”‚                 â”‚                       â”‚\nâ”‚                           â”‚ Issues?         â”‚                       â”‚\nâ”‚                           â”‚                 â”‚                       â”‚\nâ”‚                      No â”€â”€â”´â”€â”€ Yes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\nâ”‚                           â”‚                 â–²                       â”‚\nâ”‚                           â–¼                 â”‚                       â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚                       â”‚\nâ”‚                    â”‚  OUTPUT  â”‚      (repeat if needed)            â”‚\nâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThis pattern is validated by research â€” the [**Self-Refine paper**](https://arxiv.org/abs/2303.17651) (Madaan et al., 2023) shows it improves task performance by ~20% on average.\n\n**How is this different from Prompt Chaining?** Prompt chaining is predefined steps that always run the same way. Reflection is *adaptive iteration based on feedback* â€” the loop continues until the output meets criteria.\n\n**Key insight:** This is exactly what AI agents do internally. The agent node just automates this loop for you."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Challenge: Constrained Product Description\n",
    "\n",
    "To demonstrate reflection, we need a task that LLMs typically fail on the first try. Writing with **multiple hard constraints** is perfect:\n",
    "\n",
    "| Constraint | Requirement |\n",
    "|------------|-------------|\n",
    "| **Sentences** | Exactly 3 |\n",
    "| **Words** | 25â€“30 total |\n",
    "| **Keyword** | Contains \"sound\" exactly twice |\n",
    "| **Forbidden** | Does NOT contain \"music\" or \"audio\" |\n",
    "\n",
    "**Product:** Wireless Bluetooth Headphones\n",
    "\n",
    "Try asking ChatGPT to do this in one shot â€” it almost always fails at least one constraint. This is why reflection matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Two Approaches, One Pattern\n",
    "\n",
    "We'll implement the same reflection loop two ways:\n",
    "\n",
    "| Version | Who controls the loop? | Best for |\n",
    "|---------|------------------------|----------|\n",
    "| **V1: Loop with Exit** | You design the loop | When you need full control |\n",
    "| **V2: AI Agent** | AI decides when to stop | When you want simplicity |\n",
    "\n",
    "> **Import via URL** (copy and paste in n8n â†’ Import from URL):\n",
    "> ```\n",
    "> https://raw.githubusercontent.com/ezponda/ai-agents-course/main/courses/n8n_no_code/book/_static/workflows/05_reflection_pattern.json\n",
    "> ```\n",
    ">\n",
    "> **Download:** {download}`05_reflection_pattern.json <_static/workflows/05_reflection_pattern.json>`\n",
    "\n",
    "Both versions are in the same workflow. Each has its own trigger â€” run them separately and compare!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## Version 1: Loop with Exit Condition\n\nYou design a workflow that **loops until the constraints pass** (or hits a maximum of 5 iterations).\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                    LOOP                                              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\nâ”‚  â”‚ Generate/     â”‚â”€â”€â–¶â”‚   Validate    â”‚â”€â”€â–¶â”‚ Parse Result  â”‚â”€â”€â–¶â”‚  If Done?     â”‚â”€â”€â”¬â”€â”€â–¶â”‚ Output\nâ”‚  â”‚ Refine (LLM)  â”‚   â”‚    (LLM)      â”‚   â”‚    (Set)      â”‚   â”‚(pass OR max)  â”‚  â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚\nâ”‚         â–²                                                            â”‚ No       â”‚   â”‚\nâ”‚         â”‚                                                            â–¼          â”‚   â”‚\nâ”‚         â”‚                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚\nâ”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Prepare Refineâ”‚  â”‚   â”‚\nâ”‚                              (loop back)                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Pros:** Full control, predictable behavior, easy to debug\n**Cons:** More complex to build"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "::::{dropdown} ğŸ› ï¸ Build V1 (Loop) from scratch (step-by-step)\n:color: secondary\n\n### Step 1: Create a new workflow\n\n1. Click **Workflows** â†’ **Add Workflow**\n2. Rename it to \"Reflection Pattern â€” V1 Loop\"\n\n### Step 2: Add the trigger and input\n\n1. Add **Manual Trigger** â†’ rename to `Run: V1 Loop`\n2. Add **Edit Fields** â†’ rename to `Input â€” Product (V1)`\n3. Add four fields:\n\n| Name | Type | Value |\n|------|------|-------|\n| `product` | String | `Wireless Bluetooth Headphones` |\n| `constraints` | String | `- Exactly 3 sentences`<br>`- 25â€“30 words total`<br>`- Contains the word \"sound\" exactly twice`<br>`- Does NOT contain the words \"music\" or \"audio\"` |\n| `iteration` | Number | `0` |\n| `draft` | String | (leave empty) |\n\n### Step 3: Add Generate/Refine (Basic LLM Chain)\n\n1. Add **Basic LLM Chain** â†’ rename to `Generate/Refine (V1)`\n2. Configure:\n   - **Source for Prompt**: `Define below`\n   - **Prompt** (Expression mode):\n     ```\n     Product: {{ $('Input â€” Product (V1)').first().json.product }}\n\n     Constraints:\n     {{ $json.constraints }}\n\n     {{ $json.draft ? 'Previous draft:\\n' + $json.draft + '\\n\\nImprove the draft to fix the issues.' : 'Write the product description:' }}\n     ```\n3. Add System Message:\n   ```\n   You are a product copywriter.\n\n   Write a product description that meets ALL the constraints exactly.\n   Count words carefully. Output ONLY the description.\n   ```\n4. Add your Chat Model (OpenRouter, OpenAI, etc.)\n\n### Step 4: Add Store Draft (Edit Fields)\n\n1. Add **Edit Fields** â†’ rename to `Store Draft (V1)`\n2. Add three fields:\n\n| Name | Type | Value (Expression) |\n|------|------|---------------------|\n| `draft` | String | `{{ $json.text }}` |\n| `constraints` | String | `{{ $('Input â€” Product (V1)').first().json.constraints }}` |\n| `iteration` | Number | `{{ $if($('Parse Validation (V1)').isExecuted, $('Parse Validation (V1)').first().json.iteration, 0) + 1 }}` |\n\n**Why `$if(...isExecuted, ...)`?** The LLM chain only outputs `{ text }` â€” it doesn't pass through `iteration`. So Store Draft must read it from Parse Validation (a later node in the loop). On the **first** iteration Parse Validation hasn't run yet, so we use n8n's `$if($('node').isExecuted, value, default)` to return `0` when it hasn't executed, or the previous iteration's value when it has.\n\n### Step 5: Add Validate (Basic LLM Chain)\n\n1. Add **Basic LLM Chain** â†’ rename to `Validate (V1)`\n2. Configure:\n   - **Source for Prompt**: `Define below`\n   - **Prompt** (Expression):\n     ```\n     Draft:\n     {{ $json.draft }}\n\n     Constraints:\n     {{ $json.constraints }}\n\n     Validation report:\n     ```\n3. Add System Message:\n   ```\n   You are a strict validator.\n\n   Check the draft against EACH constraint:\n   1. Count sentences (must be exactly 3)\n   2. Count words (must be 25â€“30)\n   3. Count occurrences of \"sound\" (must be exactly 2)\n   4. Check for forbidden words \"music\" or \"audio\" (must have 0)\n\n   Return a JSON object:\n   {\n     \"sentences\": <number>,\n     \"words\": <number>,\n     \"sound_count\": <number>,\n     \"has_forbidden\": <true/false>,\n     \"all_pass\": <true/false>,\n     \"issues\": [\"list of issues if any\"]\n   }\n\n   Return ONLY the JSON.\n   ```\n4. Connect the same Chat Model\n\n### Step 6: Add Parse Validation (Edit Fields)\n\n1. Add **Edit Fields** â†’ rename to `Parse Validation (V1)`\n2. Add six fields:\n\n| Name | Type | Value (Expression) |\n|------|------|---------------------|\n| `draft` | String | `{{ $('Store Draft (V1)').first().json.draft }}` |\n| `constraints` | String | `{{ $('Store Draft (V1)').first().json.constraints }}` |\n| `iteration` | Number | `{{ $('Store Draft (V1)').first().json.iteration }}` |\n| `validation_json` | String | `{{ $json.text }}` |\n| `all_pass` | Boolean | `{{ /\"all_pass\"\\s*:\\s*true/.test($json.text) }}` |\n| `done` | Boolean | `{{ /\"all_pass\"\\s*:\\s*true/.test($json.text) \\|\\| $('Store Draft (V1)').first().json.iteration >= 5 }}` |\n\nThe `done` field combines both exit conditions: constraints passed **or** max iterations reached. This avoids needing a second If node.\n\n### Step 7: Add If Done? (If node)\n\n1. Add **If** â†’ rename to `If Done?`\n2. Configure the condition:\n   - **Value 1**: `{{ $json.done }}` (Expression)\n   - **Operation**: `equals`\n   - **Value 2**: `true` (Boolean)\n\n### Step 8: Add Output (V1) â€” True branch\n\n1. From the **True** output of If Done?, add **Edit Fields** â†’ rename to `Output (V1)`\n2. Add three fields:\n\n| Name | Type | Value (Expression) |\n|------|------|---------------------|\n| `final_description` | String | `{{ $json.draft }}` |\n| `iterations` | Number | `{{ $json.iteration }}` |\n| `approach` | String | `{{ $json.all_pass ? 'V1: Loop with Exit Condition' : 'V1: Loop (max iterations reached)' }}` |\n\n3. Enable **Keep Only Set**\n\n### Step 9: Add Prepare Refine (Edit Fields) â€” loop back\n\n1. From the **False** output of If Done?, add **Edit Fields** â†’ rename to `Prepare Refine (V1)`\n2. Add three fields:\n\n| Name | Type | Value (Expression) |\n|------|------|---------------------|\n| `draft` | String | `{{ $json.draft }}` |\n| `constraints` | String | `{{ $json.constraints }}` |\n| `iteration` | Number | `{{ $json.iteration }}` |\n\n3. **Connect the output of Prepare Refine back to Generate/Refine (V1)** â€” this creates the loop!\n\n### Step 10: Test\n\n1. Click **Execute Workflow**\n2. Watch the loop iterate until constraints pass (or max 5)\n3. Check how many iterations it took\n\n::::"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meet the Node: If (Conditional)\n\nThe **If** node checks a condition and sends data to one of two outputs.\n\n| Property | Description |\n|----------|-------------|\n| **Purpose** | Route data based on a condition |\n| **Outputs** | True branch (top) and False branch (bottom) |\n| **Common use** | Exit loops, handle errors, route by value |\n\nIn V1, we use one If node that combines both checks:\n- **If Done?** â€” checks if `done` is true, where `done = all_pass OR iteration >= 5`\n  - **True branch:** constraints passed or max iterations reached â†’ Output\n  - **False branch:** keep refining â†’ loop back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Parsing the Validation Result\n\nThe Validate LLM returns JSON like `{\"all_pass\": true, ...}`. We need to extract the `all_pass` value for the If node.\n\nInstead of complex JSON parsing, we use a **regex test** in an expression:\n\n```\n{{ /\"all_pass\"\\s*:\\s*true/.test($json.text) }}\n```\n\nThis returns `true` if the LLM said all constraints passed, `false` otherwise.\n\n**Regex breakdown:**\n| Part | Matches |\n|------|---------|\n| `\"all_pass\"` | The literal field name with quotes |\n| `\\s*` | Zero or more whitespace characters |\n| `:` | The colon separator |\n| `\\s*` | Zero or more whitespace characters |\n| `true` | The literal value `true` |\n\n**Why this works:**\n- The LLM is instructed to output ONLY JSON\n- We just need to know if `all_pass` is `true` â€” no need to parse the full object\n- The `\\s*` parts handle any whitespace around the colon (e.g., `\"all_pass\": true`, `\"all_pass\":true`)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Loop Works\n\nThe key to looping in n8n: **connect the output of a node back to an earlier node**.\n\n```\nGenerate/Refine â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n     â”‚                                             â”‚\n     â–¼                                             â”‚\n  Validate                                         â”‚\n     â”‚                                             â”‚\n     â–¼                                             â”‚\n  Parse Result (Set)                               â”‚\n     â”‚  (computes: done = all_pass OR iter >= 5)   â”‚\n     â–¼                                             â”‚\n  If Done? â”€â”€â”€Yesâ”€â”€â–¶ Output                        â”‚\n     â”‚                                             â”‚\n     No                                            â”‚\n     â”‚                                             â”‚\n     â–¼                                             â”‚\n  Prepare Refine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**How is the max-iteration guardrail built?** Instead of a separate If node, the `done` field in Parse Result combines both conditions: `all_pass OR iteration >= 5`. A single If node routes to Output when done, or loops back to keep refining. The Output node uses a conditional expression to report whether constraints passed or the max was hit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node-by-Node Walkthrough (V1)\n\n| Node | Type | What it does |\n|------|------|-------------|\n| **Run: V1 Loop** | Manual Trigger | Starts Version 1 |\n| **Input â€” Product (V1)** | Set | Creates `product`, `constraints`, `iteration=0`, `draft=\"\"` |\n| **Generate/Refine (V1)** | Basic LLM Chain | Generates or refines based on whether `draft` is empty |\n| **Store Draft (V1)** | Set | Saves draft and increments iteration |\n| **Validate (V1)** | Basic LLM Chain | Checks constraints, returns JSON |\n| **Parse Validation (V1)** | Set | Extracts `all_pass` boolean using regex test, computes `done` |\n| **If Done?** | If | Routes to Output if `done` (pass or max), else loops back |\n| **Prepare Refine (V1)** | Set | Formats data for next iteration |\n| **Output (V1)** | Set | Returns `final_description`, `iterations`, `approach` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Version 2: AI Agent\n",
    "\n",
    "The simplest to build: let the agent handle the loop.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                              AI AGENT                                        â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚    â”‚                    INTERNAL LOOP                                â”‚      â”‚\n",
    "â”‚    â”‚                                                                 â”‚      â”‚\n",
    "â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚      â”‚\n",
    "â”‚    â”‚   â”‚  THINK   â”‚â”€â”€â”€â”€â”€â–¶â”‚ Call Tool:   â”‚â”€â”€â”€â”€â”€â–¶â”‚  CHECK   â”‚         â”‚      â”‚\n",
    "â”‚    â”‚   â”‚          â”‚      â”‚  Validator   â”‚      â”‚          â”‚         â”‚      â”‚\n",
    "â”‚    â”‚   â”‚ \"Draft   â”‚      â”‚  (Python)    â”‚      â”‚ \"all_pass â”‚â”€â”€Noâ”€â”€â”€â”€â”¤      â”‚\n",
    "â”‚    â”‚   â”‚  a desc\" â”‚      â”‚              â”‚      â”‚  true?\"  â”‚         â”‚      â”‚\n",
    "â”‚    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚      â”‚\n",
    "â”‚    â”‚         â–²                                      â”‚               â”‚      â”‚\n",
    "â”‚    â”‚         â”‚                                      â”‚ Yes           â”‚      â”‚\n",
    "â”‚    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚      â”‚\n",
    "â”‚    â”‚                                                                 â”‚      â”‚\n",
    "â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                          â”‚\n",
    "â”‚    â”‚  Validator  â”‚ â—„â”€â”€ Python tool that checks constraints                  â”‚\n",
    "â”‚    â”‚    Tool     â”‚                                                          â”‚\n",
    "â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Pros:** Simplest to build, agent adapts strategy\n",
    "**Cons:** Less predictable, may take more iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "::::{dropdown} ğŸ› ï¸ Build V2 (Agent) from scratch (step-by-step)\n:color: secondary\n\n### Step 1: Create a new workflow\n\n1. Click **Workflows** â†’ **Add Workflow**\n2. Rename it to \"Reflection Pattern â€” V2 Agent\"\n\n### Step 2: Add the trigger and input\n\n1. Add **Manual Trigger** â†’ rename to `Run: V2 Agent`\n2. Add **Edit Fields** â†’ rename to `Input â€” Product (V2)`\n3. Add two fields:\n\n| Name | Type | Value |\n|------|------|-------|\n| `product` | String | `Wireless Bluetooth Headphones` |\n| `constraints` | String | `- Exactly 3 sentences`<br>`- 25â€“30 words total`<br>`- Contains the word \"sound\" exactly twice`<br>`- Does NOT contain the words \"music\" or \"audio\"` |\n\n### Step 3: Add the AI Agent\n\n1. Add **AI Agent** â†’ rename to `Reflection Agent (V2)`\n2. Configure:\n   - **Source for Prompt**: `Define below`\n   - **Prompt** (Expression mode):\n     ```\n     Product: {{ $json.product }}\n\n     Constraints:\n     {{ $json.constraints }}\n\n     Write a product description that meets ALL constraints. After writing, use the Validator tool to check it. Keep refining until all constraints pass.\n     ```\n3. Click **Options** â†’ Add **System Message**:\n   ```\n   You are a product copywriter who writes precise descriptions.\n\n   Process:\n   1. Write a draft description\n   2. Use the Validator tool to check it (send ONLY the description text)\n   3. Read the issues list in the Validator response to see what failed\n   4. Revise the draft to fix those specific issues\n   5. Validate again â€” repeat until all_pass is true\n   6. Return ONLY the final description\n\n   Rules:\n   - Do NOT count words yourself â€” rely on the Validator tool\n   - Send ONLY the description to the Validator (no extra text like \"Here is my draft:\")\n   - Call the Validator at most 5 times\n   - When all_pass is true, return ONLY the final description\n   ```\n\n### Step 4: Add the Chat Model (sub-node)\n\n1. Click **+ Chat Model** at the bottom of the Agent node\n2. Select **OpenRouter Chat Model** (or OpenAI, Google, etc.)\n3. Choose your credential\n4. Model: `openai/gpt-4o-mini` (or similar)\n\n### Step 5: Add the Validator Tool (Code Tool)\n\n1. Click **+ Tool** at the bottom of the Agent node\n2. Select **Code Tool**\n3. Configure:\n   - **Name**: `Validator`\n   - **Description**: `Validates a product description against constraints. Input: the description text only (no extra text). Returns JSON with: sentences (count), words (count), sound_count, has_forbidden, all_pass (true/false), and issues (list of specific problems to fix).`\n   - **Language**: `JavaScript`\n   - **JavaScript Code**:\n     ```javascript\n     // Get the raw input from the agent\n     const item = $input.first().json;\n\n     // Try common field names (varies by n8n version)\n     let description = '';\n     for (const key of ['query', 'input', 'chatInput', 'action_input']) {\n       if (item[key]) {\n         description = String(item[key]).trim();\n         break;\n       }\n     }\n\n     // Fallback: use the first non-empty string value\n     if (!description) {\n       for (const [k, v] of Object.entries(item)) {\n         if (typeof v === 'string' && v.trim()) {\n           description = v.trim();\n           break;\n         }\n       }\n     }\n\n     // Count sentences (split by . ! ?)\n     const sentences = description.split(/[.!?]+/).filter(s => s.trim());\n     const sentenceCount = sentences.length;\n\n     // Count words\n     const words = description.split(/\\s+/).filter(w => w);\n     const wordCount = words.length;\n\n     // Count \"sound\" occurrences (case insensitive, whole word)\n     const soundMatches = description.toLowerCase().match(/\\bsound\\b/g) || [];\n     const soundCount = soundMatches.length;\n\n     // Check for forbidden words\n     const hasForbidden = /\\b(music|audio)\\b/i.test(description);\n\n     // Build issues list\n     const issues = [];\n     if (sentenceCount !== 3) issues.push(`Sentences: ${sentenceCount} (need exactly 3)`);\n     if (wordCount < 25 || wordCount > 30) issues.push(`Words: ${wordCount} (need 25-30)`);\n     if (soundCount !== 2) issues.push(`\"sound\" count: ${soundCount} (need exactly 2)`);\n     if (hasForbidden) issues.push('Contains forbidden word: \"music\" or \"audio\"');\n\n     const allPass = issues.length === 0;\n\n     return [{\n       json: {\n         input_received: description.slice(0, 200),\n         sentences: sentenceCount,\n         words: wordCount,\n         sound_count: soundCount,\n         has_forbidden: hasForbidden,\n         all_pass: allPass,\n         issues: allPass ? ['All constraints passed!'] : issues\n       }\n     }];\n     ```\n\n### Step 6: Add Output (Edit Fields)\n\n1. Add **Edit Fields** â†’ rename to `Output (V2)`\n2. Add two fields:\n\n| Name | Type | Value (Expression) |\n|------|------|---------------------|\n| `final_description` | String | `{{ $json.output }}` |\n| `approach` | String | `V2: AI Agent with Validator Tool` |\n\n3. Enable **Keep Only Set**\n\n### Step 7: Test\n\n1. Click **Execute Workflow**\n2. Click the **Agent node** to see its internal tool calls\n3. Watch how it writes, validates, and refines automatically\n\n::::"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Validator Tool\n\nInstead of using an LLM to validate, V2 uses a **JavaScript Code tool** â€” a function the agent can call:\n\n```javascript\nimport re\n\n# Get the raw input from the agent\nitem = _input.first().json\n\n# Try common field names (varies by n8n version)\ndescription = ''\nfor key in ['query', 'input', 'chatInput', 'action_input']:\n    val = item.get(key, '')\n    if val:\n        description = str(val).strip()\n        break\n\n# Count sentences, words, keyword occurrences...\nsentences = [s for s in re.split(r'[.!?]+', description) if s.strip()]\nwords = [w for w in description.split() if w]\nsound_count = len(re.findall(r'\\bsound\\b', description.lower()))\nhas_forbidden = bool(re.search(r'\\b(music|audio)\\b', description, re.IGNORECASE))\n\nissues = []\nif len(sentences) != 3:\n    issues.append(f'Sentences: {len(sentences)} (need exactly 3)')\n# ... more constraint checks ...\n\nreturn [{'json': {\n    'input_received': description[:200],  # debug: see what was received\n    'all_pass': len(issues) == 0,\n    'issues': issues\n}}]\n```\n\n**Why a Python tool instead of an LLM?**\n- **Faster:** No API call needed\n- **Cheaper:** No tokens used\n- **Accurate:** Code counts exactly right (LLMs often miscount)\n\n**Key concept:** The agent doesn't \"know\" how to count â€” it *delegates* all validation to the tool. The LLM orchestrates; the code validates.\n\n**Debugging tip:** The `input_received` field shows exactly what text the Validator received. If the agent sends extra text like \"Here is my draft:\", the word count will be wrong. Check this field in the Agent node's tool call logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node-by-Node Walkthrough (V2)\n\n| Node | Type | What it does |\n|------|------|-------------|\n| **Run: V2 Agent** | Manual Trigger | Starts Version 2 |\n| **Input â€” Product (V2)** | Set | Creates `product` and `constraints` |\n| **Reflection Agent (V2)** | AI Agent | Writes, validates, refines in a loop |\n| **Validator Tool** | Code Tool | JavaScript function that checks constraints |\n| **Output (V2)** | Set | Returns `final_description` and `approach` |\n\n**Sub-nodes connected to the Agent:**\n- **OpenRouter (V2)** â€” the LLM brain\n- **Validator Tool** â€” the constraint checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Used (V2)\n\n**System Message:**\n```\nYou are a product copywriter who writes precise descriptions.\n\nProcess:\n1. Write a draft description\n2. Use the Validator tool to check it (send ONLY the description text)\n3. Read the issues list in the Validator response to see what failed\n4. Revise the draft to fix those specific issues\n5. Validate again â€” repeat until all_pass is true\n6. Return ONLY the final description\n\nRules:\n- Do NOT count words yourself â€” rely on the Validator tool\n- Send ONLY the description to the Validator (no extra text like \"Here is my draft:\")\n- Call the Validator at most 5 times\n- When all_pass is true, return ONLY the final description\n```\n\nNotice: the system message describes the reflection loop explicitly â€” including how to use the Validator's feedback. The agent follows the same pattern we built manually in V1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## The Insight: Agents Are Automated Loops\n\nCompare what each version automates:\n\n| Version | You design... | n8n handles... | AI handles... |\n|---------|---------------|----------------|---------------|\n| **V1: Loop** | The loop structure, exit condition | Looping, iteration count | Text generation |\n| **V2: Agent** | The goal and tools | Everything | The entire loop |\n\nThe agent node automates the same Generate â†’ Critique â†’ Refine loop you built by hand in V1.\n\n```{note}\n**Terminology: Evaluator-Optimizer.** Some sources call this the **Evaluator-Optimizer** pattern â€” a separate evaluator judges the output while an optimizer refines it. V1 uses a dedicated Validate LLM, V2 uses a Python tool. Pure \"reflection\" where the *same* LLM critiques its own output is a special case of this broader pattern.\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## When to Use Reflection\n\nReflection adds latency and cost. Use it strategically:\n\n| Use Reflection when... | Skip Reflection when... |\n|------------------------|-------------------------|\n| Constraints are strict and measurable | Task is simple or one-shot |\n| First-pass accuracy is typically low | Real-time / low-latency required |\n| Output quality matters more than speed | Constraints are fuzzy or subjective |\n| You can define a clear validator | No clear \"done\" criteria exists |\n\n### V1 vs V2: Which Approach?\n\n| Situation | Best approach |\n|-----------|---------------|\n| You need full control over each step | V1: Loop |\n| You want to debug exactly what's happening | V1: Loop |\n| Task is ambiguous, you want AI to adapt | V2: Agent |\n| You want the simplest implementation | V2: Agent |\n\n**General rule:** Start with V2 (agent). If you need more control or debugging, build V1."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "1. **Run both versions** on the same product\n",
    "2. **Compare:** How many iterations did each take? Which produced the best output?\n",
    "3. **Change the constraints:** Make them harder (e.g., exactly 27 words) and run again\n",
    "4. **Observe the agent:** In V2, click the agent node to see its internal tool calls\n",
    "\n",
    "**Challenge:** Modify V1 to allow up to 10 iterations. Does it ever need that many?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Reflection = Generate â†’ Critique â†’ Refine â†’ Repeat**\n",
    "2. **You can build the loop manually** (V1) or **let the agent handle it** (V2)\n",
    "3. **Agents are not magic** â€” they automate the same loop you can build by hand\n",
    "4. **Always include guardrails** (max iterations) to prevent infinite loops\n",
    "5. **Python tools are useful** when you need precise validation (LLMs miscount)\n",
    "\n",
    "**Next:** In the **First AI Agent** chapter, we'll explore more agent capabilities â€” memory, multiple tools, and conversation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}