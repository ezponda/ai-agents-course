{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# RAG: Teaching AI Your Data\n\nLLMs are trained on public internet data. They don't know about:\n- Your company's internal documents\n- Yesterday's meeting notes\n- Your product manual\n- Any private information\n\n**RAG** (Retrieval-Augmented Generation) solves this. It lets your AI search your documents and use what it finds to answer questions.\n\n```\nWITHOUT RAG                              WITH RAG\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”€â”€â”€â”€â”€â”€â”€â”€\n\nUser: \"What's our refund policy?\"        User: \"What's our refund policy?\"\n                                                        â”‚\n         â”‚                                              â–¼\n         â–¼                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚  Search your documents...   â”‚\n    â”‚   LLM   â”‚                          â”‚  Found: refund_policy.pdf   â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                                              â”‚\n         â–¼                                              â–¼\n\"I don't have access to                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n your company's policies.\"               â”‚   LLM + your document       â”‚\n                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                                        â”‚\n                                                        â–¼\n                                         \"Our refund policy allows\n                                          returns within 30 days...\"\n```\n\n**In this course, think of RAG as a Tool** â€” just like Calculator or Wikipedia. Your agent can call it when it needs facts from your documents.\n\n| | Memory | RAG |\n|--|--------|-----|\n| **Purpose** | Remember conversation history | Retrieve knowledge from files |\n| **When used** | Every message (automatic) | When agent needs specific info |\n| **Data source** | Previous messages | Your indexed documents |\n\nRAG is not chat memory. Memory keeps track of \"what did the user say earlier?\" RAG answers \"what do my documents say about this?\""
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "---\n\n## Lexical Search vs Semantic Search\n\nThere are two fundamentally different ways to search text:\n\n| | Lexical Search | Semantic Search |\n|--|----------------|-----------------|\n| **How it works** | Matches exact words | Matches meaning |\n| **Also called** | Keyword search, full-text search | Vector search, similarity search |\n| **Strength** | Fast, precise for exact terms | Understands synonyms, context |\n| **Weakness** | Misses synonyms and related concepts | Can miss exact matches (IDs, codes) |\n\n### The Vocabulary Mismatch Problem\n\nLexical search has a fundamental flaw: people use different words for the same thing.\n\n```\nYOUR DOCUMENTS SAY:                    USER SEARCHES FOR:\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\"Return items within 30 days           \"refund policy\"\n for a full credit.\"\n                                              â”‚\n\"Contact customer care for                    â”‚\n assistance with exchanges.\"                  â–¼\n\n                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                              â”‚    LEXICAL SEARCH       â”‚\n                              â”‚                         â”‚\n                              â”‚  \"refund\" â‰  \"return\"    â”‚\n                              â”‚  \"policy\" â‰  \"credit\"    â”‚\n                              â”‚                         â”‚\n                              â”‚      âŒ NO MATCH        â”‚\n                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nThe document ANSWERS the question, but the WORDS don't match.\n```\n\nThis is called the **vocabulary mismatch problem**. Real examples:\n\n| User searches for... | Document says... | Lexical finds it? |\n|---------------------|------------------|-------------------|\n| \"laptop\" | \"notebook computer\" | No |\n| \"car issues\" | \"vehicle problems\" | No |\n| \"how to cancel\" | \"termination process\" | No |\n| \"cheap flights\" | \"budget airfare\" | No |\n\n### Semantic Search Solves This\n\nSemantic search converts text to numbers that represent **meaning**, not just words.\n\n```\nUSER QUERY: \"refund policy\"         YOUR DOCUMENTS:\n           â†“                        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    [meaning vector]                \"Return items within 30 days\" â†’ [meaning vector]\n           â†“                        \"Contact customer care...\"    â†’ [meaning vector]\n           â†“                        \"Shipping takes 3-5 days\"     â†’ [meaning vector]\n           â†“\n           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                          â–¼\n              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n              â”‚   SEMANTIC SEARCH       â”‚\n              â”‚                         â”‚\n              â”‚  Compare meanings...    â”‚\n              â”‚                         â”‚\n              â”‚  âœ“ \"Return items...\"    â”‚  â† closest meaning\n              â”‚  âœ— \"Contact customer..\" â”‚\n              â”‚  âœ— \"Shipping takes...\"  â”‚\n              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThe words \"refund\" and \"return\" are different, but their **meanings** are close â€” so semantic search finds the match."
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": "---\n\n## Embeddings: How Semantic Search Works\n\nHow does semantic search know that \"refund\" and \"return\" are related? Through **embeddings**.\n\nAn **embedding** is a list of numbers (called a \"vector\") that captures the meaning of text. Think of it as translating words into coordinates on a map.\n\n```\nTEXT                              EMBEDDING (simplified)\nâ”€â”€â”€â”€                              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\"king\"                     â†’      [0.2, 0.8, 0.1, ...]\n\"queen\"                    â†’      [0.2, 0.8, 0.3, ...]\n\"apple\"                    â†’      [0.9, 0.1, 0.2, ...]\n```\n\nNotice: \"king\" and \"queen\" have similar numbers because they're related concepts. \"apple\" is completely different.\n\n### Similar Meanings = Close Vectors\n\nImagine a map where related concepts cluster together:\n\n```\n                    â–²\n                    â”‚\n         \"queen\" â—  â”‚  â— \"king\"\n                    â”‚\n        \"princess\" â—â”‚â— \"prince\"\n                    â”‚\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶\n                    â”‚\n                    â”‚      â— \"apple\"\n                    â”‚  â— \"banana\"\n                    â”‚      â— \"orange\"\n                    â”‚\n\n    Royalty clusters together.    Fruits cluster together.\n    Far apart from each other.\n```\n\nWhen you search for \"monarch\", the system:\n1. Converts \"monarch\" to a vector\n2. Finds vectors closest to it on the map\n3. Returns \"king\" and \"queen\" â€” even though the word \"monarch\" doesn't appear anywhere\n\n### Who Creates the Embeddings?\n\nEmbedding models (like OpenAI's `text-embedding-3-small`) are trained on massive amounts of text to learn these meaning-relationships. You don't need to understand how they work â€” just know that:\n\n- Same embedding model must be used for indexing AND querying\n- Different models produce different vectors (not compatible)\n- Embedding API calls have a cost (but much cheaper than LLM calls)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vector Stores: A Database for Meanings\n",
    "\n",
    "A **vector store** is a database optimized for storing and searching embeddings.\n",
    "\n",
    "```\n",
    "TRADITIONAL DATABASE                   VECTOR STORE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ID  â”‚  Text           â”‚             â”‚  ID  â”‚  Text  â”‚ Vector â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  1   â”‚  \"Return items  â”‚             â”‚  1   â”‚  ...   â”‚ [0.2,  â”‚\n",
    "â”‚      â”‚   within 30...\" â”‚             â”‚      â”‚        â”‚  0.8]  â”‚\n",
    "â”‚  2   â”‚  \"Contact us at â”‚             â”‚  2   â”‚  ...   â”‚ [0.5,  â”‚\n",
    "â”‚      â”‚   support@...\"  â”‚             â”‚      â”‚        â”‚  0.3]  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Search: WHERE text LIKE '%refund%'     Search: Find vectors closest to\n",
    "Result: Nothing found                          [0.2, 0.7] (\"refund policy\")\n",
    "                                       Result: Document 1 (closest match)\n",
    "```\n",
    "\n",
    "The vector store doesn't look for matching words â€” it finds documents whose *meaning* is closest to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": "---\n\n## The RAG Pipeline: Two Separate Workflows\n\nRAG requires **two separate workflows** in n8n:\n\n| Workflow | When to run | What it does |\n|----------|-------------|--------------|\n| **Indexing** | Once (or when docs change) | Load â†’ Chunk â†’ Embed â†’ Store |\n| **Chat/Agent** | Every user question | Embed query â†’ Search â†’ Answer |\n\nThis separation is important: you don't re-index your documents every time someone asks a question.\n\n### Workflow 1: Indexing (Build Your Knowledge Base)\n\nRun this once to prepare your documents (or schedule it to run periodically if docs change):\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Your Docs  â”‚â”€â”€â”€â–¶â”‚   Chunker   â”‚â”€â”€â”€â–¶â”‚  Embeddings â”‚â”€â”€â”€â–¶â”‚Vector Store â”‚\nâ”‚  (PDF, txt) â”‚    â”‚(split text) â”‚    â”‚(textâ†’vector)â”‚    â”‚  (save)     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nExample:\nâ”€â”€â”€â”€â”€â”€â”€â”€\npolicy.pdf          \"Return items      [0.2, 0.8, ...]     Stored and\n(10 pages)    â†’     within 30 days\"  â†’                  â†’  ready to\n                    (100 chunks)       (100 vectors)       search\n```\n\n### Workflow 2: Chat/Agent (Answer Questions)\n\nRun this every time a user asks something:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    User     â”‚â”€â”€â”€â–¶â”‚  Embeddings â”‚â”€â”€â”€â–¶â”‚Vector Store â”‚â”€â”€â”€â–¶â”‚     LLM     â”‚\nâ”‚   Question  â”‚    â”‚(queryâ†’vector)â”‚   â”‚  (search)   â”‚    â”‚  (answer)   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                             â”‚\n                                             â–¼\n                                      Top 3 relevant\n                                         chunks\n\nExample:\nâ”€â”€â”€â”€â”€â”€â”€â”€\n\"What's your         [0.2, 0.7]       \"Return items       \"Our refund policy\n refund policy?\"  â†’                â†’  within 30 days...\" â†’ allows returns\n                     (query vector)   (most similar)       within 30 days...\"\n```\n\nThe LLM receives your question *plus* the relevant document chunks. Now it can answer accurately using **only** the provided context."
  },
  {
   "cell_type": "markdown",
   "id": "d7pd33mhbnv",
   "source": "---\n\n## Why Chunking Matters\n\nYou might wonder: why not just send the entire document to the LLM? Three reasons:\n\n### 1. Context Window Limits\n\nLLMs can only process a limited amount of text at once â€” this is called the **context window**. Different models have different limits, but even the largest context windows can't fit hundreds of pages of documentation.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         LLM CONTEXT WINDOW                                  â”‚\nâ”‚                                                                             â”‚\nâ”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚    â”‚  System prompt + User question + Retrieved chunks + Response      â”‚   â”‚\nâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                                             â”‚\nâ”‚    Context windows range from ~16K to ~200K tokens depending on model      â”‚\nâ”‚    One token â‰ˆ 4 characters in English (roughly 0.75 words)                â”‚\nâ”‚                                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nIf your company has 500 pages of documentation, it won't fit. You need to retrieve just the relevant parts.\n\n### 2. Cost Efficiency\n\nLLM pricing is based on tokens processed. More tokens = higher cost.\n\n```\nAPPROACH 1: Send everything                APPROACH 2: RAG\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nYour docs: 500 pages                       Your docs: 500 pages\n                                                  â”‚\n         â”‚                                        â–¼\n         â–¼                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚   Search    â”‚\nâ”‚  500 pages â†’ LLM    â”‚                    â”‚  \"refund\"   â”‚\nâ”‚                     â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ”‚  ğŸ’° Expensive       â”‚                           â”‚\nâ”‚  â±ï¸ Slow            â”‚                           â–¼\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                                           â”‚  3 chunks   â”‚\n                                           â”‚  â†’ LLM      â”‚\n                                           â”‚             â”‚\n                                           â”‚ ğŸ’° Cheap    â”‚\n                                           â”‚ â±ï¸ Fast     â”‚\n                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nRAG is typically **much cheaper** because you only send a few relevant chunks, not hundreds of pages.\n\n### 3. Focus and Accuracy\n\nWhen LLMs receive too much text, they can get \"lost\" â€” missing important details buried in irrelevant content. Smaller, focused chunks lead to better answers.\n\n```\n                    TOO MUCH CONTEXT\n                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Page 1: Company history...                              â”‚\nâ”‚ Page 2: Mission statement...                            â”‚\nâ”‚ Page 3: Team bios...                                    â”‚\nâ”‚ ...                                                     â”‚\nâ”‚ Page 47: Refund policy (30 days, receipt required)  â—€â”€â”€ â”‚ Important!\nâ”‚ ...                                                     â”‚\nâ”‚ Page 98: Holiday hours...                               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n    LLM might miss page 47 buried in 98 pages of text.\n\n\n                    FOCUSED CONTEXT (RAG)\n                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Chunk: \"Return items within 30 days with receipt for    â”‚\nâ”‚         full refund. Exchanges available within 60...\"  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n    LLM has exactly what it needs to answer.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "b2nvkf4luwo",
   "source": "---\n\n## Chunking Strategies\n\nHow you split documents affects everything. Bad chunks = bad retrieval = bad answers.\n\n### The Chunking Trade-off\n\n```\nCHUNK SIZE SPECTRUM\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nToo Small (50 tokens)           Just Right (300-800)           Too Large (2000+ tokens)\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\"Returns within\"                \"Return items within           \"Return items within 30\n                                 30 days with receipt           days with receipt for full\n\"30 days with\"                   for full refund.               refund. Exchanges available\n                                 Exchanges available            within 60 days. Contact\n\"receipt for full\"               within 60 days.\"               customer service at... [long\n                                                                paragraph about shipping,\n                                                                store hours, etc.]\"\n\nâŒ Lost context                  âœ“ Complete thought             âŒ Too much noise\nâŒ Fragments don't make sense    âœ“ Focused                      âŒ Irrelevant info retrieved\nâŒ Many chunks to search         âœ“ Searchable                   âŒ Wastes context window\n```\n\n### Chunk Overlap\n\nOverlap prevents cutting sentences in half and losing context at boundaries.\n\n```\nWITHOUT OVERLAP                         WITH OVERLAP (20%)\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nDocument: \"Our refund policy allows returns within 30 days.\n           A receipt is required for all returns.\"\n\nChunk 1: \"Our refund policy allows\"     Chunk 1: \"Our refund policy allows\n                                                  returns within 30 days.\"\nChunk 2: \"returns within 30 days.\"      \n                                        Chunk 2: \"returns within 30 days.\nChunk 3: \"A receipt is required\"                  A receipt is required\n                                                  for all returns.\"\nChunk 4: \"for all returns.\"\n                                        The overlap ensures complete\nâŒ \"returns within 30 days\" is cut       sentences are preserved.\n   off from \"refund policy\"\n```\n\n**Typical settings:** Chunk size 500-1000 tokens, overlap 10-20%.\n\n### What Happens with Large PDFs?\n\nProcessing a 200-page PDF:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                          200-PAGE PDF PROCESSING                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nStep 1: LOAD                    Step 2: SPLIT                  Step 3: EMBED\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   200 pages  â”‚               â”‚  ~400 chunks â”‚               â”‚ 400 vectors  â”‚\nâ”‚   (~100,000  â”‚      â†’        â”‚  (500 tokens â”‚      â†’        â”‚  stored in   â”‚\nâ”‚    words)    â”‚               â”‚   each)      â”‚               â”‚ vector store â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n                  Text Splitter              Embedding Model\n                  breaks into               converts each chunk\n                  manageable pieces         to a vector\n\n\nStep 4: QUERY\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nUser: \"What's the refund policy?\"\n\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Search 400 vectors â†’ Return top 3-5 most relevant chunks â†’ Send to LLM     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nResult: Only ~2,500 tokens sent to LLM (not 100,000!)\n```\n\n### Chunking Strategies Comparison\n\n| Strategy | How it works | Best for |\n|----------|--------------|----------|\n| **Fixed size** | Split every N characters | Simple, predictable |\n| **Recursive** | Split by paragraphs, then sentences, then words | Most documents (recommended) |\n| **By page** | Each PDF page = one chunk | Documents where pages are self-contained |\n| **By section** | Split at headers (##, ###) | Markdown, structured docs |\n\nn8n's **Recursive Character Text Splitter** is the most versatile â€” it tries to keep paragraphs together, then sentences, then words.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "---\n\n## RAG Components in n8n\n\nn8n provides nodes for each step of the RAG pipeline:\n\n| Component | n8n Node | What it does |\n|-----------|----------|-------------|\n| **Document Loader** | Default Data Loader, GitHub, Google Drive | Reads your files |\n| **Text Splitter** | Recursive Character Text Splitter | Breaks docs into chunks |\n| **Embeddings** | OpenAI Embeddings, Ollama Embeddings | Converts text â†’ vectors |\n| **Vector Store** | Simple Vector Store, Supabase, Pinecone | Stores and searches vectors |\n\n### Vector Store Options\n\n| Option | Best for | Notes |\n|--------|----------|-------|\n| **Simple Vector Store** | Learning, small projects | In-memory, no setup needed |\n| **Supabase** | Production with PostgreSQL | Free tier available |\n| **Pinecone** | Large-scale production | Managed service |\n| **Qdrant** | Self-hosted production | Open source |\n\nFor this course, we'll use **Simple Vector Store** â€” it works immediately without any external database setup.\n\n> **Warning: Simple Vector Store Limitations**\n>\n> - **Not persistent**: Data is stored in memory and **can be erased when n8n restarts**\n> - **Shared access**: All users on the same n8n instance can access the stored data\n> - **Not for production**: Don't use it for confidential documents or real applications\n>\n> For production, use a proper vector database (Supabase, Pinecone, Qdrant).\n\n### RAG as an Agent Tool\n\nFor agents, n8n provides the **Vector Store Question Answer Tool**. This packages RAG as a tool your agent can call:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                              AI AGENT                                       â”‚\nâ”‚                                                                             â”‚\nâ”‚    Agent receives question â†’ Decides to use RAG tool â†’ Gets answer          â”‚\nâ”‚                                                                             â”‚\nâ”‚    Tools available:                                                         â”‚\nâ”‚    â”œâ”€â”€ Calculator                                                           â”‚\nâ”‚    â”œâ”€â”€ Wikipedia                                                            â”‚\nâ”‚    â””â”€â”€ Vector Store QA Tool  â—€â”€â”€ Searches your indexed documents           â”‚\nâ”‚                                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThis is the recommended pattern for agents that need to answer questions from your documents.\n\n**Docs:** [RAG in n8n](https://docs.n8n.io/advanced-ai/rag-in-n8n/) | [Vector Store Question Answer Tool](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolvectorstore/)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG vs Fine-Tuning vs Long Context\n",
    "\n",
    "There are other ways to give LLMs custom knowledge. When should you use RAG?\n",
    "\n",
    "| Approach | How it works | Best for |\n",
    "|----------|--------------|----------|\n",
    "| **RAG** | Search docs at query time | Facts that change, large doc collections |\n",
    "| **Fine-tuning** | Retrain the model on your data | Teaching new skills or style |\n",
    "| **Long context** | Paste entire docs in the prompt | Small, static documents |\n",
    "\n",
    "### When to Choose RAG\n",
    "\n",
    "```\n",
    "                        Use RAG when:\n",
    "                        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  âœ“ Documents change frequently (policies, product info)        â”‚\n",
    "â”‚  âœ“ Too many documents to fit in one prompt                     â”‚\n",
    "â”‚  âœ“ You need citations (\"where did this answer come from?\")     â”‚\n",
    "â”‚  âœ“ Different users need access to different documents          â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                        DON'T use RAG when:\n",
    "                        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                                 â”‚\n",
    "â”‚  âœ— You have just 1-2 small documents (paste in prompt instead) â”‚\n",
    "â”‚  âœ— You want to change HOW the model writes (fine-tune instead) â”‚\n",
    "â”‚  âœ— The info is already in the model's training data            â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": "---\n\n## Common RAG Challenges\n\nRAG isn't magic. Here are common issues and how to handle them:\n\n| Challenge | What happens | Solution |\n|-----------|--------------|----------|\n| **Wrong chunks retrieved** | Semantic search finds unrelated text | Improve chunking, add metadata filters |\n| **Answer not in docs** | LLM hallucinates an answer anyway | Add \"only answer from context\" instruction |\n| **Chunks too small** | Missing context around the answer | Increase chunk size or overlap |\n| **Chunks too large** | Irrelevant text included | Decrease chunk size |\n| **Outdated embeddings** | New docs not searchable | Re-run indexing pipeline |\n| **Slow queries** | Vector search takes too long | Use faster vector store, reduce chunk count |\n\n### Hallucination Prevention\n\nEven with RAG, LLMs may invent answers when the context doesn't contain the information. Add this to your system prompt:\n\n```\nAnswer ONLY based on the provided context.\nIf the answer is not in the context, say \"I don't have information about that.\"\nDo not make up information.\n```\n\n### When Semantic Search Fails\n\nSemantic search has blind spots â€” it can miss:\n\n| What it misses | Example | Solution |\n|----------------|---------|----------|\n| **Exact IDs/codes** | \"Order #12345\" | Add keyword search (hybrid) |\n| **Acronyms** | \"What does HIPAA mean?\" | Expand acronyms in docs |\n| **Very specific terms** | Technical jargon | Ensure terms appear in training data |\n\nFor production systems, **hybrid search** (semantic + lexical) often works best."
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": "---\n\n## Summary\n\n| Concept | Key Point |\n|---------|----------|\n| **RAG** | Retrieval-Augmented Generation â€” search your docs, then answer |\n| **Lexical vs Semantic** | Keyword matching vs meaning matching |\n| **Vocabulary mismatch** | Why keyword search fails (\"refund\" â‰  \"return\") |\n| **Embeddings** | Convert text to vectors that capture meaning |\n| **Vector Store** | Database optimized for similarity search |\n| **Context Window** | LLMs can only process limited text â€” RAG retrieves what's relevant |\n| **Chunking** | Split docs into searchable pieces (500-1000 tokens typical) |\n| **Overlap** | Prevents losing context at chunk boundaries (10-20%) |\n\n**Key insight:** RAG makes LLMs useful for your private data without retraining. Instead of stuffing everything into the prompt (expensive, slow, unfocused), you search for relevant chunks and send only those."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}